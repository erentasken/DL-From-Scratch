{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e14df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59477700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99418479 0.52639739 0.54737383]\n",
      "[0.49145897 0.64064141 0.41850929]\n",
      "0.4886010361832088\n",
      "0.33723196541317807\n",
      "0.22908103440740685\n",
      "1.0549140360037936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.05491404],\n",
       "       [0.96642359],\n",
       "       [1.16506167]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.random((3,3))\n",
    "\n",
    "b = np.random.random((3,1))\n",
    "\n",
    "# print(a)\n",
    "\n",
    "print(a[0,:])\n",
    "print(b[:,0])\n",
    "\n",
    "\n",
    "sum = 0\n",
    "for x, y in zip(a[0,:], b[:,0]):\n",
    "    # print( x * y)\n",
    "    print ( x * y )\n",
    "    sum += x * y\n",
    "print(sum)\n",
    "\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8427b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(-5,5)\n",
    "\n",
    "(a > 0).astype(error_tensor.dtypeint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4b4257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Layers.ReLU.ReLU object at 0x7f3eaca74980>\n"
     ]
    }
   ],
   "source": [
    "from Layers.ReLU import ReLU\n",
    "\n",
    "relu = ReLU()\n",
    "print(relu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "698de5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1252404022027295e-10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Optimization import Loss\n",
    "\n",
    "a = np.array([[1,0,0], [0,1,0]])\n",
    "a = np.clip(a, 1e-12, 1.0 - 1e-12)\n",
    "\n",
    "from Optimization import Loss\n",
    "cr = Loss.CrossEntropyLoss()\n",
    "print(cr.forward(a, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09e9fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23357165 0.29718911 0.46923924]\n",
      " [0.39339784 0.27062234 0.33597982]\n",
      " [0.20164957 0.4032543  0.39509613]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(3,3)\n",
    "\n",
    "b = np.max(a, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "exp = np.exp(a-b)\n",
    "sum_exp = np.sum(exp, axis=1, keepdims=True)\n",
    "pred =exp / sum_exp \n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "933b1391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        , -0.        , -0.        ],\n",
       "       [-0.        ,  1.30703101, -0.        ],\n",
       "       [-0.        , -0.        ,  0.92862617]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.array([\n",
    "    [1, 0, 0],  # sample 1 → class 0\n",
    "    [0, 1, 0],  # sample 2 → class 1\n",
    "    [0, 0, 1]   # sample 3 → class 2\n",
    "])\n",
    "\n",
    "pred[0][0] = 1\n",
    "\n",
    "-label * np.log(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "09836232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original softmax prediction:\n",
      "[[0.28188344 0.22521579 0.19752971 0.29537107]\n",
      " [0.22061411 0.39674304 0.19574306 0.18689979]\n",
      " [0.24022556 0.24305049 0.1463345  0.37038946]\n",
      " [0.15820561 0.2760891  0.21909182 0.34661347]\n",
      " [0.12329175 0.2737069  0.31191427 0.29108709]\n",
      " [0.16439043 0.27880138 0.25063562 0.30617257]\n",
      " [0.32101742 0.32134521 0.14818323 0.20945414]\n",
      " [0.26621765 0.26792908 0.26327419 0.20257908]\n",
      " [0.17373739 0.30391441 0.19506105 0.32728716]]\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "\n",
      "\n",
      "Cross-entropy result (element-wise):\n",
      "[[1.26626164 0.         0.         0.        ]\n",
      " [0.         0.92446647 0.         0.        ]\n",
      " [1.42617698 0.         0.         0.        ]\n",
      " [0.         0.         0.         1.05954504]\n",
      " [2.09320181 0.         0.         0.        ]\n",
      " [1.80551104 0.         0.         0.        ]\n",
      " [0.         1.13523931 0.         0.        ]\n",
      " [0.         0.         1.33455925 0.        ]\n",
      " [0.         0.         0.         1.11691732]]\n",
      "\n",
      "Total Loss = 12.161878867160498\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# random prediction matrix\n",
    "a = np.random.rand(9, 4)\n",
    "\n",
    "# stable softmax\n",
    "b = np.max(a, axis=1, keepdims=True)\n",
    "exp = np.exp(a - b)\n",
    "sum_exp = np.sum(exp, axis=1, keepdims=True)\n",
    "pred = exp / sum_exp\n",
    "\n",
    "print(\"Original softmax prediction:\")\n",
    "print(pred)\n",
    "\n",
    "# Label tensor (one-hot)\n",
    "label = np.array([\n",
    "    [1, 0, 0],   # sample 1 → class 0\n",
    "    [0, 1, 0],   # sample 2 → class 1\n",
    "    [0, 0, 1]    # sample 3 → class 2\n",
    "])\n",
    "\n",
    "label = np.zeros([9, 4])\n",
    "for i in range(9):\n",
    "    label[i, np.random.randint(0, 4)] = 1\n",
    "\n",
    "print(label)\n",
    "print()\n",
    "# Cross-entropy term -y * log(y_hat)\n",
    "ce_matrix = -label * np.log(pred)    # stability (same as your tests)\n",
    "\n",
    "print(\"\\nCross-entropy result (element-wise):\")\n",
    "print(ce_matrix)\n",
    "\n",
    "loss = np.sum(ce_matrix)\n",
    "print(\"\\nTotal Loss =\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853d3b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax prediction (first sample): [0.1748777  0.47536689 0.1748777  0.1748777 ]\n",
      "Loss: 15.693015425658114\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "batch_size = 9   # match what the original test expects\n",
    "categories = 4\n",
    "\n",
    "# one-hot labels\n",
    "label_tensor = np.zeros((batch_size, categories))\n",
    "label_tensor[:, 2] = 1  # correct class is 2\n",
    "\n",
    "# input logits\n",
    "input_tensor = np.zeros_like(label_tensor)\n",
    "input_tensor[:, 1] = 1  # model predicts class 1 strongly\n",
    "\n",
    "# CrossEntropyLoss (logits version)\n",
    "def cross_entropy_with_logits(logits, labels):\n",
    "    shifted = logits - np.max(logits, axis=1, keepdims=True)\n",
    "    log_sum_exp = np.log(np.sum(np.exp(shifted), axis=1, keepdims=True))\n",
    "    log_softmax = shifted - log_sum_exp\n",
    "    loss = -np.sum(labels * log_softmax)\n",
    "    return loss, np.exp(log_softmax)\n",
    "\n",
    "loss, softmax_pred = cross_entropy_with_logits(input_tensor, label_tensor)\n",
    "\n",
    "print(\"Softmax prediction (first sample):\", softmax_pred[0])\n",
    "print(\"Loss:\", loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
